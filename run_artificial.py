import numpy as np 
import pandas as pd
import networkx as nx
import seaborn as sns; sns.set()
import matplotlib.pyplot as plt
sns.set_style("white")
from sklearn.metrics.pairwise import rbf_kernel
from sklearn.preprocessing import Normalizer, MinMaxScaler
from scipy.sparse import csgraph  
import scipy
import os 
from sklearn import datasets
from linucb import LINUCB
from gob import GOB 
from utils import *
path='bandit_results/simulated/'

user_num=30
item_num=30
dimension=30
pool_size=10
iteration=1000
num_trials=10
sigma=0.01# noise
delta=0.01# high probability
alpha=1 # regularizer
alpha_2=0.15# edge delete CLUB
epsilon=8 # Ts
beta=0.125 # exploration for CLUB, SCLUB and GOB
thres=0.0
state=False # False for artificial dataset, True for real dataset

user_seq=np.random.choice(range(user_num), size=iteration)
item_pool_seq=np.random.choice(range(item_num), size=(iteration, pool_size))
item_feature_matrix=Normalizer().fit_transform(np.random.normal(size=(item_num, dimension)))

sbm_adj=SBM_graph(user_num)

# Draw the SBM graph
G = nx.from_numpy_array(sbm_adj)
nx.draw(G, with_labels=True)
plt.title('Graph generated by SBM')
plt.savefig(path+'sbm_graph.png', dpi=100)

# Construct the Laplacian matrix
true_adj=sbm_adj.copy()
true_adj += np.eye(user_num)  # Add self-loop
D=np.diag(np.sum(true_adj, axis=1))
true_lap=np.zeros((user_num, user_num))
for i in range(user_num):
	for j in range(user_num):
		if D[i,i]==0:
			true_lap[i,j]=0
		else:
			true_lap[i,j]=-true_adj[i,j]/D[i,i]
np.fill_diagonal(true_lap, 1)

linucb_regret_matrix=np.zeros((num_trials, iteration))
linucb_error_matrix=np.zeros((num_trials, iteration))
constructed_gob_regret_matrix=np.zeros((num_trials, iteration))
constructed_gob_error_matrix=np.zeros((num_trials, iteration))


# Graph filter
def H(L, alpha=1.0):
	return scipy.linalg.inv(np.identity(L.shape[0]) + alpha*L)


# Constructing a cluster graph representation from payoff signals
observation_num = 30
constructed_adj = np.zeros((user_num, user_num))
payoff_history = H(true_lap)@np.random.normal(size=(dimension, observation_num))
cov_payoff = np.cov(payoff_history)
# Find top K eigenvectors of the covariance matrix
K = 3
eigenvalues, eigenvectors = np.linalg.eig(cov_payoff)
top_K_eigenvectors = eigenvectors[:, np.argsort(eigenvalues)[-K:]]
# Apply k-means method to cluster the eigenvectors
from sklearn.cluster import KMeans
kmeans = KMeans(n_clusters=K, random_state=0).fit(top_K_eigenvectors)
cluster_labels = kmeans.labels_
# Construct the cluster graph
for i in range(user_num):
	for j in range(i, user_num):
		if cluster_labels[i] == cluster_labels[j]:
			constructed_adj[i, j] = 1
			constructed_adj[j, i] = 1
# Construct the Laplacian matrix
constructed_lap = csgraph.laplacian(constructed_adj, normed=True)

# No information graph
empty_adj = np.identity(user_num)
empty_lap = csgraph.laplacian(empty_adj, normed=True)


for l in range(num_trials):
	print(f'Trial {l}/{num_trials}')
	user_feature_matrix = H(constructed_lap)@np.random.normal(size=(user_num, dimension))
	true_payoffs=np.dot(user_feature_matrix, item_feature_matrix.T)

	linucb_model=LINUCB(dimension, iteration, user_num, item_num, pool_size, item_feature_matrix, user_feature_matrix, true_payoffs, alpha, delta, sigma, state)
	constructed_gob_model=GOB(dimension, iteration, user_num, item_num, pool_size, item_feature_matrix, user_feature_matrix, true_payoffs, constructed_adj, constructed_lap, alpha, delta, sigma, beta, state)

	linucb_regret, linucb_error, linucb_beta, linucb_x_norm, linucb_inst_regret, linucb_ucb, linucb_sum_x_norm, linucb_real_beta=linucb_model.run(user_seq, item_pool_seq, iteration)
	constructed_gob_regret, constructed_gob_error, constructed_gob_beta, constructed_gob_x_norm, constructed_gob_ucb, constructed_gob_sum_x_norm, constructed_gob_real_beta = constructed_gob_model.run(user_seq, item_pool_seq, iteration)

	linucb_regret_matrix[l], linucb_error_matrix[l]=linucb_regret, linucb_error
	constructed_gob_regret_matrix[l], constructed_gob_error_matrix[l]=constructed_gob_regret, constructed_gob_error


linucb_mean=np.mean(linucb_regret_matrix, axis=0)
linucb_sd=linucb_regret_matrix.std(0)

constructed_gob_mean=np.mean(constructed_gob_regret_matrix, axis=0)
constructed_gob_sd=constructed_gob_regret_matrix.std(0)
x=range(iteration)
plt.figure(figsize=(5,5))
plt.plot(x, linucb_mean, '-.', markevery=0.1, linewidth=2, markersize=8, label='LinUCB')
plt.fill_between(x, linucb_mean-linucb_sd, linucb_mean+linucb_sd, color='b', alpha=0.2)
plt.plot(x, constructed_gob_mean, '-o', color='r', markevery=0.1, linewidth=2, markersize=8, label='Gob.Lin_Constructed')
plt.fill_between(x, constructed_gob_mean-constructed_gob_sd, constructed_gob_mean+constructed_gob_sd, color='r', alpha=0.2)
plt.ylabel('Cumulative Regret', fontsize=16)
plt.xlabel('Time', fontsize=16)
plt.legend(loc=2, fontsize=14)
plt.tight_layout()
plt.savefig(path+'regret.png', dpi=100)
